{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T18:30:13.204024Z",
     "start_time": "2026-02-05T18:30:13.191772Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Requirements\n",
    "\n",
    "# From GeoNames (https://www.geonames.org/export/):\n",
    "## cities15000.txt\n",
    "## countryInfo.txt (https://download.geonames.org/export/dump/countryInfo.txt)\n",
    "\n",
    "# %pip install pandas flashtext unidecode wordninja"
   ],
   "id": "1536bf4a64b60a7f",
   "outputs": [],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T18:30:13.918444Z",
     "start_time": "2026-02-05T18:30:13.204745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# connect to mongoDB\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "MONGO_URI = \"/\" # connection URI here\n",
    "\n",
    "client = MongoClient(MONGO_URI)\n",
    "\n",
    "client.list_database_names()"
   ],
   "id": "a9a2d121bfe1b6d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw-scrape-data', 'admin', 'local']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T18:30:14.015079Z",
     "start_time": "2026-02-05T18:30:13.925171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# select database and collection\n",
    "\n",
    "db = client[\"raw-scrape-data\"]\n",
    "collection = db[\"tiktok-user-data\"]\n",
    "\n",
    "collection.count_documents({})\n"
   ],
   "id": "6267acbbe8d74474",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7415"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 87
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T18:30:14.611036Z",
     "start_time": "2026-02-05T18:30:14.017292Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# load data into pandas (excluding the fields related to the scrape run)\n",
    "# this is not limited - lading all records in\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "cursor = collection.find(\n",
    "    {},\n",
    "    {\n",
    "        \"_id\": 0,\n",
    "        \"username\": 1,\n",
    "        \"run_finished_at\": 1,\n",
    "        \"video_id\": 1,\n",
    "        \"caption\": 1,\n",
    "        \"timestamp\": 1,\n",
    "        \"duration_sec\": 1,\n",
    "        \"view_count\": 1,\n",
    "        \"like_count\": 1,\n",
    "        \"comment_count\": 1,\n",
    "        \"repost_count\": 1,\n",
    "        \"hashtags\": 1\n",
    "    }\n",
    ")\n",
    "\n",
    "docs = list(cursor)\n",
    "df = pd.DataFrame(docs)\n",
    "\n",
    "df.head()"
   ],
   "id": "9855006dcf4e88bf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          run_finished_at    username             video_id  \\\n",
       "0 2026-02-02 03:12:20.410  visitdubai  7601573860256894228   \n",
       "1 2026-02-02 03:12:20.410  visitdubai  7600024923301530900   \n",
       "2 2026-02-02 03:12:20.410  visitdubai  7599717255353552148   \n",
       "3 2026-02-02 03:12:20.410  visitdubai  7597750555636813076   \n",
       "4 2026-02-02 03:12:20.410  visitdubai  7596781431444065556   \n",
       "\n",
       "                                             caption   timestamp  \\\n",
       "0  our beautiful beautiful city #Dubai #VisitDuba...  1769879340   \n",
       "1  200km/h through the sky. Ciel Dubai Marina jus...  1769518701   \n",
       "2  Dubai but make it cinematic ‚ù§Ô∏è‚Äçüî• #VisitDubai #...  1769447068   \n",
       "3                     2016 ü§† #VisitDubai #Dubai #fyp  1768989160   \n",
       "4                lucky me ‚ò∫Ô∏è #VisitDubai #Dubai #fyp  1768763520   \n",
       "\n",
       "   duration_sec  view_count  like_count  comment_count  repost_count  \\\n",
       "0          21.0        1276          98              6             3   \n",
       "1          51.0        1175          48              2             2   \n",
       "2          15.0        1717         118              4             4   \n",
       "3          60.0       51200        5977             42           497   \n",
       "4          12.0        2215         109              5             5   \n",
       "\n",
       "                                hashtags  \n",
       "0                   dubai,visitdubai,fyp  \n",
       "1  xdubai,visitdubai,dubai,thefirstgroup  \n",
       "2                   visitdubai,dubai,fyp  \n",
       "3                   visitdubai,dubai,fyp  \n",
       "4                   visitdubai,dubai,fyp  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_finished_at</th>\n",
       "      <th>username</th>\n",
       "      <th>video_id</th>\n",
       "      <th>caption</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>view_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>repost_count</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-02-02 03:12:20.410</td>\n",
       "      <td>visitdubai</td>\n",
       "      <td>7601573860256894228</td>\n",
       "      <td>our beautiful beautiful city #Dubai #VisitDuba...</td>\n",
       "      <td>1769879340</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1276</td>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>dubai,visitdubai,fyp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-02-02 03:12:20.410</td>\n",
       "      <td>visitdubai</td>\n",
       "      <td>7600024923301530900</td>\n",
       "      <td>200km/h through the sky. Ciel Dubai Marina jus...</td>\n",
       "      <td>1769518701</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1175</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>xdubai,visitdubai,dubai,thefirstgroup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-02-02 03:12:20.410</td>\n",
       "      <td>visitdubai</td>\n",
       "      <td>7599717255353552148</td>\n",
       "      <td>Dubai but make it cinematic ‚ù§Ô∏è‚Äçüî• #VisitDubai #...</td>\n",
       "      <td>1769447068</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1717</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>visitdubai,dubai,fyp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-02-02 03:12:20.410</td>\n",
       "      <td>visitdubai</td>\n",
       "      <td>7597750555636813076</td>\n",
       "      <td>2016 ü§† #VisitDubai #Dubai #fyp</td>\n",
       "      <td>1768989160</td>\n",
       "      <td>60.0</td>\n",
       "      <td>51200</td>\n",
       "      <td>5977</td>\n",
       "      <td>42</td>\n",
       "      <td>497</td>\n",
       "      <td>visitdubai,dubai,fyp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2026-02-02 03:12:20.410</td>\n",
       "      <td>visitdubai</td>\n",
       "      <td>7596781431444065556</td>\n",
       "      <td>lucky me ‚ò∫Ô∏è #VisitDubai #Dubai #fyp</td>\n",
       "      <td>1768763520</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2215</td>\n",
       "      <td>109</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>visitdubai,dubai,fyp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T18:30:14.662182Z",
     "start_time": "2026-02-05T18:30:14.612167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Convert timestamps to posted date/time\n",
    "\n",
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], unit=\"s\", errors=\"coerce\")\n",
    "df.rename(columns={\"timestamp\": \"posted_date_time\"}, inplace=True)\n",
    "\n",
    "df[\"run_finished_at\"] = pd.to_datetime(df[\"run_finished_at\"], unit=\"s\", errors=\"coerce\")\n",
    "df.rename(columns={\"run_finished_at\": \"scraped_at\"}, inplace=True)\n",
    "\n",
    "df.head()\n"
   ],
   "id": "13b0f78f4cf73086",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               scraped_at    username             video_id  \\\n",
       "0 2026-02-02 03:12:20.410  visitdubai  7601573860256894228   \n",
       "1 2026-02-02 03:12:20.410  visitdubai  7600024923301530900   \n",
       "2 2026-02-02 03:12:20.410  visitdubai  7599717255353552148   \n",
       "3 2026-02-02 03:12:20.410  visitdubai  7597750555636813076   \n",
       "4 2026-02-02 03:12:20.410  visitdubai  7596781431444065556   \n",
       "\n",
       "                                             caption    posted_date_time  \\\n",
       "0  our beautiful beautiful city #Dubai #VisitDuba... 2026-01-31 17:09:00   \n",
       "1  200km/h through the sky. Ciel Dubai Marina jus... 2026-01-27 12:58:21   \n",
       "2  Dubai but make it cinematic ‚ù§Ô∏è‚Äçüî• #VisitDubai #... 2026-01-26 17:04:28   \n",
       "3                     2016 ü§† #VisitDubai #Dubai #fyp 2026-01-21 09:52:40   \n",
       "4                lucky me ‚ò∫Ô∏è #VisitDubai #Dubai #fyp 2026-01-18 19:12:00   \n",
       "\n",
       "   duration_sec  view_count  like_count  comment_count  repost_count  \\\n",
       "0          21.0        1276          98              6             3   \n",
       "1          51.0        1175          48              2             2   \n",
       "2          15.0        1717         118              4             4   \n",
       "3          60.0       51200        5977             42           497   \n",
       "4          12.0        2215         109              5             5   \n",
       "\n",
       "                                hashtags  \n",
       "0                   dubai,visitdubai,fyp  \n",
       "1  xdubai,visitdubai,dubai,thefirstgroup  \n",
       "2                   visitdubai,dubai,fyp  \n",
       "3                   visitdubai,dubai,fyp  \n",
       "4                   visitdubai,dubai,fyp  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>username</th>\n",
       "      <th>video_id</th>\n",
       "      <th>caption</th>\n",
       "      <th>posted_date_time</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>view_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>repost_count</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-02-02 03:12:20.410</td>\n",
       "      <td>visitdubai</td>\n",
       "      <td>7601573860256894228</td>\n",
       "      <td>our beautiful beautiful city #Dubai #VisitDuba...</td>\n",
       "      <td>2026-01-31 17:09:00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1276</td>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>dubai,visitdubai,fyp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-02-02 03:12:20.410</td>\n",
       "      <td>visitdubai</td>\n",
       "      <td>7600024923301530900</td>\n",
       "      <td>200km/h through the sky. Ciel Dubai Marina jus...</td>\n",
       "      <td>2026-01-27 12:58:21</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1175</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>xdubai,visitdubai,dubai,thefirstgroup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-02-02 03:12:20.410</td>\n",
       "      <td>visitdubai</td>\n",
       "      <td>7599717255353552148</td>\n",
       "      <td>Dubai but make it cinematic ‚ù§Ô∏è‚Äçüî• #VisitDubai #...</td>\n",
       "      <td>2026-01-26 17:04:28</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1717</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>visitdubai,dubai,fyp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-02-02 03:12:20.410</td>\n",
       "      <td>visitdubai</td>\n",
       "      <td>7597750555636813076</td>\n",
       "      <td>2016 ü§† #VisitDubai #Dubai #fyp</td>\n",
       "      <td>2026-01-21 09:52:40</td>\n",
       "      <td>60.0</td>\n",
       "      <td>51200</td>\n",
       "      <td>5977</td>\n",
       "      <td>42</td>\n",
       "      <td>497</td>\n",
       "      <td>visitdubai,dubai,fyp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2026-02-02 03:12:20.410</td>\n",
       "      <td>visitdubai</td>\n",
       "      <td>7596781431444065556</td>\n",
       "      <td>lucky me ‚ò∫Ô∏è #VisitDubai #Dubai #fyp</td>\n",
       "      <td>2026-01-18 19:12:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2215</td>\n",
       "      <td>109</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>visitdubai,dubai,fyp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T18:30:14.673462Z",
     "start_time": "2026-02-05T18:30:14.663437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a copy to preserve the raw data frame\n",
    "\n",
    "df_raw = df.copy()\n",
    "df = df_raw.copy()\n"
   ],
   "id": "aceb7f22370fd82b",
   "outputs": [],
   "execution_count": 90
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T18:30:14.702234Z",
     "start_time": "2026-02-05T18:30:14.673899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# hashtags into a list for analysis later\n",
    "\n",
    "df[\"hashtags_list\"] = (\n",
    "    df[\"hashtags\"]\n",
    "    .fillna(\"\")\n",
    "    .astype(str)\n",
    "    .str.lower()\n",
    "    .str.replace(r\"\\s+\", \"\", regex=True)\n",
    "    .str.split(\",\")\n",
    "    .apply(lambda lst: [t for t in lst if t])\n",
    ")\n",
    "\n",
    "df.head()\n"
   ],
   "id": "ac8d241b4a57078b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "               scraped_at    username             video_id  \\\n",
       "0 2026-02-02 03:12:20.410  visitdubai  7601573860256894228   \n",
       "1 2026-02-02 03:12:20.410  visitdubai  7600024923301530900   \n",
       "2 2026-02-02 03:12:20.410  visitdubai  7599717255353552148   \n",
       "3 2026-02-02 03:12:20.410  visitdubai  7597750555636813076   \n",
       "4 2026-02-02 03:12:20.410  visitdubai  7596781431444065556   \n",
       "\n",
       "                                             caption    posted_date_time  \\\n",
       "0  our beautiful beautiful city #Dubai #VisitDuba... 2026-01-31 17:09:00   \n",
       "1  200km/h through the sky. Ciel Dubai Marina jus... 2026-01-27 12:58:21   \n",
       "2  Dubai but make it cinematic ‚ù§Ô∏è‚Äçüî• #VisitDubai #... 2026-01-26 17:04:28   \n",
       "3                     2016 ü§† #VisitDubai #Dubai #fyp 2026-01-21 09:52:40   \n",
       "4                lucky me ‚ò∫Ô∏è #VisitDubai #Dubai #fyp 2026-01-18 19:12:00   \n",
       "\n",
       "   duration_sec  view_count  like_count  comment_count  repost_count  \\\n",
       "0          21.0        1276          98              6             3   \n",
       "1          51.0        1175          48              2             2   \n",
       "2          15.0        1717         118              4             4   \n",
       "3          60.0       51200        5977             42           497   \n",
       "4          12.0        2215         109              5             5   \n",
       "\n",
       "                                hashtags  \\\n",
       "0                   dubai,visitdubai,fyp   \n",
       "1  xdubai,visitdubai,dubai,thefirstgroup   \n",
       "2                   visitdubai,dubai,fyp   \n",
       "3                   visitdubai,dubai,fyp   \n",
       "4                   visitdubai,dubai,fyp   \n",
       "\n",
       "                                hashtags_list  \n",
       "0                    [dubai, visitdubai, fyp]  \n",
       "1  [xdubai, visitdubai, dubai, thefirstgroup]  \n",
       "2                    [visitdubai, dubai, fyp]  \n",
       "3                    [visitdubai, dubai, fyp]  \n",
       "4                    [visitdubai, dubai, fyp]  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>username</th>\n",
       "      <th>video_id</th>\n",
       "      <th>caption</th>\n",
       "      <th>posted_date_time</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>view_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>repost_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>hashtags_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-02-02 03:12:20.410</td>\n",
       "      <td>visitdubai</td>\n",
       "      <td>7601573860256894228</td>\n",
       "      <td>our beautiful beautiful city #Dubai #VisitDuba...</td>\n",
       "      <td>2026-01-31 17:09:00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1276</td>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>dubai,visitdubai,fyp</td>\n",
       "      <td>[dubai, visitdubai, fyp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2026-02-02 03:12:20.410</td>\n",
       "      <td>visitdubai</td>\n",
       "      <td>7600024923301530900</td>\n",
       "      <td>200km/h through the sky. Ciel Dubai Marina jus...</td>\n",
       "      <td>2026-01-27 12:58:21</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1175</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>xdubai,visitdubai,dubai,thefirstgroup</td>\n",
       "      <td>[xdubai, visitdubai, dubai, thefirstgroup]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2026-02-02 03:12:20.410</td>\n",
       "      <td>visitdubai</td>\n",
       "      <td>7599717255353552148</td>\n",
       "      <td>Dubai but make it cinematic ‚ù§Ô∏è‚Äçüî• #VisitDubai #...</td>\n",
       "      <td>2026-01-26 17:04:28</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1717</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>visitdubai,dubai,fyp</td>\n",
       "      <td>[visitdubai, dubai, fyp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2026-02-02 03:12:20.410</td>\n",
       "      <td>visitdubai</td>\n",
       "      <td>7597750555636813076</td>\n",
       "      <td>2016 ü§† #VisitDubai #Dubai #fyp</td>\n",
       "      <td>2026-01-21 09:52:40</td>\n",
       "      <td>60.0</td>\n",
       "      <td>51200</td>\n",
       "      <td>5977</td>\n",
       "      <td>42</td>\n",
       "      <td>497</td>\n",
       "      <td>visitdubai,dubai,fyp</td>\n",
       "      <td>[visitdubai, dubai, fyp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2026-02-02 03:12:20.410</td>\n",
       "      <td>visitdubai</td>\n",
       "      <td>7596781431444065556</td>\n",
       "      <td>lucky me ‚ò∫Ô∏è #VisitDubai #Dubai #fyp</td>\n",
       "      <td>2026-01-18 19:12:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2215</td>\n",
       "      <td>109</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>visitdubai,dubai,fyp</td>\n",
       "      <td>[visitdubai, dubai, fyp]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 91
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T18:30:14.727292Z",
     "start_time": "2026-02-05T18:30:14.704147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove duplicates\n",
    "\n",
    "before = len(df) #curious how many are dropped\n",
    "\n",
    "subset_cols = [c for c in [\"video_id\", \"scraped_at\", \"url\", \"username\"] if c in df.columns]\n",
    "df = df.drop_duplicates(subset=subset_cols)\n",
    "\n",
    "after = len(df)\n",
    "print(f\"Exact duplicates dropped (subset={subset_cols}): {before - after}\") # exact dropped\n",
    "\n",
    "before = len(df)\n",
    "\n",
    "df = df.sort_values(\"scraped_at\").drop_duplicates(subset=[\"video_id\"], keep=\"last\")\n",
    "\n",
    "after = len(df)\n",
    "print(f\"Duplicate video_id rows dropped (kept latest scraped_at): {before - after}\") # duplicate videos"
   ],
   "id": "71cf3b36130f46",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact duplicates dropped (subset=['video_id', 'scraped_at', 'username']): 0\n",
      "Duplicate video_id rows dropped (kept latest scraped_at): 90\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T18:30:14.757926Z",
     "start_time": "2026-02-05T18:30:14.727814Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# standardize numeric datatypes\n",
    "\n",
    "metric_cols = [\"view_count\",\"like_count\",\"comment_count\",\"repost_count\",\"save_count\",\"duration\",\"duration_sec\"]\n",
    "for c in metric_cols:\n",
    "    if c in df.columns:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# unify duration naming\n",
    "if \"duration_sec\" in df.columns and \"duration\" not in df.columns:\n",
    "    df.rename(columns={\"duration_sec\":\"duration_s\"}, inplace=True)\n",
    "elif \"duration\" in df.columns:\n",
    "    df.rename(columns={\"duration\":\"duration_s\"}, inplace=True)\n",
    "\n",
    "# update null counts to 0\n",
    "for c in [\"view_count\",\"like_count\",\"comment_count\",\"repost_count\",\"save_count\"]:\n",
    "    if c in df.columns:\n",
    "        df[c] = df[c].fillna(0).astype(\"int64\")\n",
    "\n",
    "df.head()"
   ],
   "id": "60e6df2115195414",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                scraped_at      username             video_id  \\\n",
       "0  2026-02-02 03:12:20.410    visitdubai  7601573860256894228   \n",
       "91 2026-02-02 03:12:20.410  visitbritain  7590782903961799958   \n",
       "90 2026-02-02 03:12:20.410  visitbritain  7590783895868673302   \n",
       "89 2026-02-02 03:12:20.410  visitbritain  7590777080816700694   \n",
       "88 2026-02-02 03:12:20.410  visitbritain  7592675902580854038   \n",
       "\n",
       "                                              caption    posted_date_time  \\\n",
       "0   our beautiful beautiful city #Dubai #VisitDuba... 2026-01-31 17:09:00   \n",
       "91  Avengers, assemble in Norfolk! ü¶∏‚Äç‚ôÄÔ∏è  Join Meli... 2026-01-08 18:00:00   \n",
       "90  Join Charlie as he dives into the drama, the h... 2026-01-10 15:00:00   \n",
       "89  Off-grid, with limited electricity and no Wi-F... 2026-01-11 15:00:00   \n",
       "88  A real-life location from a legendary TV show,... 2026-01-13 18:00:00   \n",
       "\n",
       "    duration_s  view_count  like_count  comment_count  repost_count  \\\n",
       "0         21.0        1276          98              6             3   \n",
       "91        18.0         944          96              1             5   \n",
       "90        50.0         599          53              3             0   \n",
       "89        10.0         428          29              0             2   \n",
       "88         9.0         603          23              6             1   \n",
       "\n",
       "                                             hashtags  \\\n",
       "0                                dubai,visitdubai,fyp   \n",
       "91  starringgreatbritain,avengers,marvel,avengersf...   \n",
       "90     rabycastle,castlebritain,durham,britainhistory   \n",
       "89                                                NaN   \n",
       "88  starringgreatbritain,filmtourism,birmingham,bl...   \n",
       "\n",
       "                                        hashtags_list  \n",
       "0                            [dubai, visitdubai, fyp]  \n",
       "91  [starringgreatbritain, avengers, marvel, aveng...  \n",
       "90  [rabycastle, castlebritain, durham, britainhis...  \n",
       "89                                                 []  \n",
       "88  [starringgreatbritain, filmtourism, birmingham...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scraped_at</th>\n",
       "      <th>username</th>\n",
       "      <th>video_id</th>\n",
       "      <th>caption</th>\n",
       "      <th>posted_date_time</th>\n",
       "      <th>duration_s</th>\n",
       "      <th>view_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>repost_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>hashtags_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2026-02-02 03:12:20.410</td>\n",
       "      <td>visitdubai</td>\n",
       "      <td>7601573860256894228</td>\n",
       "      <td>our beautiful beautiful city #Dubai #VisitDuba...</td>\n",
       "      <td>2026-01-31 17:09:00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1276</td>\n",
       "      <td>98</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>dubai,visitdubai,fyp</td>\n",
       "      <td>[dubai, visitdubai, fyp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>2026-02-02 03:12:20.410</td>\n",
       "      <td>visitbritain</td>\n",
       "      <td>7590782903961799958</td>\n",
       "      <td>Avengers, assemble in Norfolk! ü¶∏‚Äç‚ôÄÔ∏è&nbsp;&nbsp;Join Meli...</td>\n",
       "      <td>2026-01-08 18:00:00</td>\n",
       "      <td>18.0</td>\n",
       "      <td>944</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>starringgreatbritain,avengers,marvel,avengersf...</td>\n",
       "      <td>[starringgreatbritain, avengers, marvel, aveng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>2026-02-02 03:12:20.410</td>\n",
       "      <td>visitbritain</td>\n",
       "      <td>7590783895868673302</td>\n",
       "      <td>Join Charlie as he dives into the drama, the h...</td>\n",
       "      <td>2026-01-10 15:00:00</td>\n",
       "      <td>50.0</td>\n",
       "      <td>599</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>rabycastle,castlebritain,durham,britainhistory</td>\n",
       "      <td>[rabycastle, castlebritain, durham, britainhis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>2026-02-02 03:12:20.410</td>\n",
       "      <td>visitbritain</td>\n",
       "      <td>7590777080816700694</td>\n",
       "      <td>Off-grid, with limited electricity and no Wi-F...</td>\n",
       "      <td>2026-01-11 15:00:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>428</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2026-02-02 03:12:20.410</td>\n",
       "      <td>visitbritain</td>\n",
       "      <td>7592675902580854038</td>\n",
       "      <td>A real-life location from a legendary TV show,...</td>\n",
       "      <td>2026-01-13 18:00:00</td>\n",
       "      <td>9.0</td>\n",
       "      <td>603</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>starringgreatbritain,filmtourism,birmingham,bl...</td>\n",
       "      <td>[starringgreatbritain, filmtourism, birmingham...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T18:45:45.572229Z",
     "start_time": "2026-02-05T18:45:44.376479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### GEO NAMES ###\n",
    "\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "from flashtext import KeywordProcessor\n",
    "\n",
    "CITIES_PATH = \"geonames/cities15000.txt\"\n",
    "COUNTRIES_PATH = \"geonames/countryInfo.txt\"\n",
    "\n",
    "def norm(s: str) -> str:\n",
    "    \"\"\"Normalize text: lowercase, remove accents, keep alnum/spaces/#/_.\"\"\"\n",
    "    s = unidecode(str(s).lower())\n",
    "    s = re.sub(r\"[^a-z0-9\\s#_]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def load_cities(cities_path: str) -> pd.DataFrame:\n",
    "    # GeoNames cities15000 format (tab-delimited, no header)\n",
    "    cols = [\n",
    "        \"geonameid\",\"name\",\"asciiname\",\"alternatenames\",\"latitude\",\"longitude\",\n",
    "        \"feature_class\",\"feature_code\",\"country_code\",\"cc2\",\"admin1_code\",\"admin2_code\",\n",
    "        \"admin3_code\",\"admin4_code\",\"population\",\"elevation\",\"dem\",\"timezone\",\"modification_date\"\n",
    "    ]\n",
    "    dfc = pd.read_csv(cities_path, sep=\"\\t\", names=cols, dtype=str, header=None)\n",
    "    dfc[\"population\"] = pd.to_numeric(dfc[\"population\"], errors=\"coerce\").fillna(0).astype(int)\n",
    "    return dfc\n",
    "\n",
    "def load_countries(country_info_path: str) -> pd.DataFrame:\n",
    "    # countryInfo.txt is tab-delimited with comment lines starting with #\n",
    "    rows = []\n",
    "    with open(country_info_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            if not line.strip() or line.startswith(\"#\"):\n",
    "                continue\n",
    "            parts = line.rstrip(\"\\n\").split(\"\\t\")\n",
    "            rows.append(parts)\n",
    "    # columns per GeoNames docs\n",
    "    cols = [\n",
    "        \"ISO\",\"ISO3\",\"ISO_Numeric\",\"fips\",\"Country\",\"Capital\",\"Area\",\"Population\",\"Continent\",\n",
    "        \"tld\",\"CurrencyCode\",\"CurrencyName\",\"Phone\",\"PostalCodeFormat\",\"PostalCodeRegex\",\n",
    "        \"Languages\",\"geonameid\",\"neighbours\",\"EquivalentFipsCode\"\n",
    "    ]\n",
    "    dfcty = pd.DataFrame(rows, columns=cols)\n",
    "    return dfcty\n",
    "\n",
    "def build_city_matcher(dfc: pd.DataFrame, min_pop: int = 50000) -> tuple[KeywordProcessor, dict]:\n",
    "    \"\"\"\n",
    "    Build FlashText matcher mapping MANY names -> canonical city label.\n",
    "    Canonical label: \"City, CC\" (e.g. \"Dubai, AE\") to reduce ambiguity.\n",
    "    Returns matcher and canonical->metadata map.\n",
    "    \"\"\"\n",
    "    kp = KeywordProcessor(case_sensitive=False)\n",
    "    canonical_meta = {}\n",
    "\n",
    "    df_use = dfc[dfc[\"population\"] >= min_pop].copy()\n",
    "\n",
    "    for _, r in df_use.iterrows():\n",
    "        name = \"\" if pd.isna(r[\"name\"]) else str(r[\"name\"])\n",
    "        asciiname = \"\" if pd.isna(r[\"asciiname\"]) else str(r[\"asciiname\"])\n",
    "        alt = \"\" if pd.isna(r[\"alternatenames\"]) else str(r[\"alternatenames\"])\n",
    "        cc = \"\" if pd.isna(r[\"country_code\"]) else str(r[\"country_code\"]).strip()\n",
    "\n",
    "        canonical = f\"{name}, {cc}\" if cc else name\n",
    "        canonical_meta[canonical] = {\n",
    "            \"geonameid\": r[\"geonameid\"],\n",
    "            \"name\": name,\n",
    "            \"country_code\": cc,\n",
    "            \"population\": int(r[\"population\"]),\n",
    "        }\n",
    "\n",
    "        # Add normalized variants\n",
    "        variants = set()\n",
    "\n",
    "        for v in [name, asciiname]:\n",
    "            v = norm(v)\n",
    "            if v:\n",
    "                variants.add(v)\n",
    "\n",
    "        # alternatenames is comma-separated\n",
    "        for v in alt.split(\",\"):\n",
    "            v = norm(v)\n",
    "            if v:\n",
    "                variants.add(v)\n",
    "\n",
    "        # Add into FlashText\n",
    "        for v in variants:\n",
    "            # Avoid very short tokens (noise)\n",
    "            if len(v) < 3:\n",
    "                continue\n",
    "            kp.add_keyword(v, canonical)\n",
    "\n",
    "    return kp, canonical_meta\n",
    "\n",
    "def build_country_matcher(dfcty: pd.DataFrame) -> KeywordProcessor:\n",
    "    \"\"\"\n",
    "    Build FlashText matcher for countries.\n",
    "    Canonical: Country name (GeoNames 'Country' column).\n",
    "    \"\"\"\n",
    "    kp = KeywordProcessor(case_sensitive=False)\n",
    "\n",
    "    for _, r in dfcty.iterrows():\n",
    "        country = r[\"Country\"]\n",
    "        iso2 = r[\"ISO\"]\n",
    "        iso3 = r[\"ISO3\"]\n",
    "\n",
    "        canonical = country\n",
    "\n",
    "        variants = set()\n",
    "        for v in [country, iso2, iso3]:\n",
    "            v = norm(v)\n",
    "            if v:\n",
    "                variants.add(v)\n",
    "\n",
    "        # Add \"united states\"/\"u s a\" style spacing variants lightly\n",
    "        # (We do NOT hardcode huge alias lists; this is tiny formatting normalization)\n",
    "        for v in list(variants):\n",
    "            variants.add(v.replace(\" \", \"\"))\n",
    "\n",
    "        for v in variants:\n",
    "            if len(v) < 2:\n",
    "                continue\n",
    "            kp.add_keyword(v, canonical)\n",
    "\n",
    "    # Optional tiny overrides for common non-country region labels in social text\n",
    "    # (Minimal + targeted; delete if you want strictly GeoNames-only)\n",
    "    overrides = {\n",
    "        \"great britain\": \"United Kingdom\",\n",
    "        \"britain\": \"United Kingdom\",\n",
    "        \"uk\": \"United Kingdom\",\n",
    "        \"u k\": \"United Kingdom\",\n",
    "        \"united kingdom\": \"United Kingdom\",\n",
    "    }\n",
    "    for k, v in overrides.items():\n",
    "        kp.add_keyword(norm(k), v)\n",
    "        kp.add_keyword(norm(k).replace(\" \", \"\"), v)\n",
    "\n",
    "    return kp\n",
    "\n",
    "# Load + build matchers\n",
    "df_cities = load_cities(CITIES_PATH)\n",
    "df_countries = load_countries(COUNTRIES_PATH)\n",
    "\n",
    "city_kp, city_meta = build_city_matcher(df_cities, min_pop=50000)   # tune threshold\n",
    "country_kp = build_country_matcher(df_countries)\n",
    "\n",
    "len(city_meta), df_countries.shape"
   ],
   "id": "2847bf80abb0c3fd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11788, (252, 19))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T18:47:30.499854Z",
     "start_time": "2026-02-05T18:47:30.391886Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Build full text from available cols\n",
    "text_cols = [c for c in [\"caption\", \"description\", \"title\"] if c in df.columns]\n",
    "df[\"full_text\"] = (\n",
    "    df[text_cols].fillna(\"\").astype(str).agg(\" \".join, axis=1)\n",
    "    if text_cols else \"\"\n",
    ")\n",
    "\n",
    "if \"hashtags_list\" not in df.columns and \"hashtags\" in df.columns:\n",
    "    df[\"hashtags_list\"] = (\n",
    "        df[\"hashtags\"].fillna(\"\").astype(str).str.lower()\n",
    "        .str.replace(r\"\\s+\", \"\", regex=True)\n",
    "        .str.split(\",\")\n",
    "        .apply(lambda lst: [t for t in lst if t])\n",
    "    )\n"
   ],
   "id": "fbf443873611bb70",
   "outputs": [],
   "execution_count": 103
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T18:49:38.808686Z",
     "start_time": "2026-02-05T18:49:35.768431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# create a new columns for locations\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_hashtag_tokens_from_text(text: str) -> list[str]:\n",
    "    return re.findall(r\"#([a-z0-9_]+)\", norm(text))\n",
    "\n",
    "def combine_tokens(row):\n",
    "    toks = []\n",
    "    if \"hashtags_list\" in row and isinstance(row[\"hashtags_list\"], list):\n",
    "        toks.extend(row[\"hashtags_list\"])\n",
    "    toks.extend(extract_hashtag_tokens_from_text(row.get(\"full_text\", \"\")))\n",
    "    return toks\n",
    "\n",
    "def location_extract_row(row):\n",
    "    full_text = norm(row.get(\"full_text\", \"\"))\n",
    "\n",
    "    tokens = combine_tokens(row)\n",
    "\n",
    "    # Build hashtag phrase candidates (handles visitdubai, starringgreatbritain)\n",
    "    phrases = set()\n",
    "    for tok in tokens:\n",
    "        split_words = wordninja.split(norm(tok).replace(\"#\",\"\").replace(\"_\",\"\"))\n",
    "        # add n-grams up to length 4\n",
    "        for i in range(len(split_words)):\n",
    "            for n in range(1, 5):\n",
    "                j = i + n\n",
    "                if j <= len(split_words):\n",
    "                    phrase = \" \".join(split_words[i:j])\n",
    "                    phrases.add(phrase)\n",
    "                    phrases.add(phrase.replace(\" \", \"\"))\n",
    "\n",
    "        # raw token variants too\n",
    "        nt = norm(tok)\n",
    "        phrases.add(nt)\n",
    "        phrases.add(nt.replace(\" \", \"\"))\n",
    "\n",
    "    # Match\n",
    "    countries = set(country_kp.extract_keywords(full_text))\n",
    "    cities = set(city_kp.extract_keywords(full_text))\n",
    "\n",
    "    for p in phrases:\n",
    "        countries.update(country_kp.extract_keywords(p))\n",
    "        cities.update(city_kp.extract_keywords(p))\n",
    "\n",
    "    # light noise control: if too many cities, keep top 10 by pop\n",
    "    if len(cities) > 10:\n",
    "        cities = set(sorted(cities, key=lambda c: city_meta.get(c, {}).get(\"population\", 0), reverse=True)[:10])\n",
    "\n",
    "    cities = sorted(cities)\n",
    "    countries = sorted(countries)\n",
    "    locations = sorted(set(cities) | set(countries))\n",
    "\n",
    "    return cities, countries, locations\n",
    "\n",
    "df[\"cities_mentioned\"], df[\"countries_mentioned\"], df[\"locations_mentioned\"] = zip(\n",
    "    *df.apply(location_extract_row, axis=1)\n",
    ")\n"
   ],
   "id": "8779a0354729c20d",
   "outputs": [],
   "execution_count": 105
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-05T18:49:57.412727Z",
     "start_time": "2026-02-05T18:49:57.364748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# validate\n",
    "\n",
    "df.explode(\"locations_mentioned\")[\"locations_mentioned\"].value_counts().head(25)\n"
   ],
   "id": "850de6cdce14aed",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "locations_mentioned\n",
       "Teresina, BR            3120\n",
       "India                   2884\n",
       "Tonga                   2805\n",
       "Andorra                 2281\n",
       "Fortaleza, BR           1887\n",
       "Italy                   1629\n",
       "Iceland                 1574\n",
       "Malaysia                 989\n",
       "Austria                  936\n",
       "Dominican Republic       801\n",
       "Thika, KE                746\n",
       "Somalia                  718\n",
       "United Arab Emirates     714\n",
       "Canada                   697\n",
       "Arecibo, PR              668\n",
       "Caen, FR                 610\n",
       "Belgium                  598\n",
       "Dayton, US               556\n",
       "Montenegro               545\n",
       "Buta, CD                 469\n",
       "Washington, US           467\n",
       "Reunion                  463\n",
       "American Samoa           462\n",
       "Netherlands Antilles     456\n",
       "London, GB               452\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 106
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. Does the column exist?\n",
    "df.columns\n",
    "\n"
   ],
   "id": "b74e7d67f2b25492",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
